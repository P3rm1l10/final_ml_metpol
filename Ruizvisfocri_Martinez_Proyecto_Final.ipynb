{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d1fc53-d94b-4499-817d-babbcb01e6b1",
   "metadata": {},
   "source": [
    "# Proyecto final Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6795c-ca8c-440d-bfeb-9b7607685711",
   "metadata": {},
   "source": [
    "Jorge Ruizvisfocri\n",
    "\n",
    "Emilio Martinez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a7f13-99cc-46fe-a2cb-7f7bafe43117",
   "metadata": {},
   "source": [
    "# Descripción del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d469410-9a0e-4207-9278-5fe08489dffe",
   "metadata": {},
   "source": [
    "El siguiente proyecto busca clasificar imágenes de Carcinomas Ductales Invasivos (IDC en inglés) extraidas de muestras de pacientes con cancer de mama.\n",
    "\n",
    "La base de datos fue tomada de https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images\n",
    "\n",
    "Se propone utilizar una red neuronal convolucional para resolver el problema de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61434f9f-74a5-4dc9-ad23-b654c5949587",
   "metadata": {},
   "source": [
    "# Paqueterías de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c300dce-540b-42bd-a5b5-b8a14977d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paquetes de ciencias de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import math\n",
    "import random\n",
    "\n",
    "## Paquetes de lectura de imagenes\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "\n",
    "## Paquetes de imágenes\n",
    "from skimage.io import imread\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d47ff47-7aa4-469d-9694-113bfeac7d62",
   "metadata": {},
   "source": [
    "# Datos de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74b69f5-85ae-4e92-8d98-1da5c635cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de imágenes\n",
    "data_dir = Path(\"D://bases de datos//proyecto_ml_final//imagenes\") ## Directorio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1eb82a-b910-47a6-a3d1-fcc431b716e2",
   "metadata": {},
   "source": [
    "Dado que todos los pacientes tienen muestras con tumores malignos y benignos, la aleatorización puede realizarse a nivel de imagen o a nivel de paciente.\n",
    "\n",
    "Bajo el supuesto de que podría existir correlación de algún tipo entre las imágenes pertenecientes a un mismo paciente, creemos que sería interesante aleatorizar a nivel de paciente, para introducirle a la red la información de personas que jamás ha visto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ba3705-8755-4f5a-a53d-dfc487503281",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aleatorización a nivel de paciente\n",
    "#### Obtenemos la lista de pacientes\n",
    "px = [f for f in data_dir.iterdir() if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c287e8-2951-4e57-afce-25b89086617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Obtenemos el número equivalente al porcentaje deseado\n",
    "k = math.ceil( len(px) * 80 // 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db14f1fd-217c-4779-a803-1bef7cc3b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hacemos la muestra de pacientes para entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d71ef82-8a3e-47b5-a8b3-6b45e7bda23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fijamos la semilla para tener reproductibilidad\n",
    "random.seed(4352)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b8cba47-2ad2-476a-b6d4-ed92d1e40714",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = random.sample(px,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f427d55e-c414-4879-8be7-0176db51250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = set(px) - set(train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c6dd66-db7a-4b6d-9677-8c4f98bf6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "### cargamos files de entrenamiento\n",
    "train_images_files = []\n",
    "for p in train_id:\n",
    "    img_lst = list(p.rglob(\"*.png\"))\n",
    "    train_images_files.extend(img_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b54b8fb0-5222-4e3a-85f4-b6629b21cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_files = []\n",
    "for p in test_id:\n",
    "    img_lst = list(p.rglob(\"*.png\"))\n",
    "    test_images_files.extend(img_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2694b47-372e-4572-a031-7ce7f90cc5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagenes\n",
      "-----------------\n",
      "Total: 277524\n",
      "-----------------\n",
      "Entrenamiento: 220389\n",
      "-----------------\n",
      "Prueba: 57135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Revisamos que las direcciones de las imágenes estén bien cargadas\n",
    "print(\n",
    "    f\"Número de imagenes\\n\"\n",
    "    \"-----------------\\n\"\n",
    "    f\"Total: {len(train_images_files) + len(test_images_files) }\\n\"  # 277,524 tiles\n",
    "    \"-----------------\\n\"\n",
    "    f\"Entrenamiento: {len(train_images_files) }\\n\"\n",
    "    \"-----------------\\n\"\n",
    "    f\"Prueba: {len(test_images_files) }\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984508a-0785-4ac4-bdfb-32a840c306f9",
   "metadata": {},
   "source": [
    "## Preparamos las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0131a0b1-a854-49d1-9fe2-0327ddb64e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## y_entrenamiento\n",
    "### Preparamos las etiquetas\n",
    "y_train = []\n",
    "for name in train_images_files:\n",
    "    etiqueta = str(name)[-5]\n",
    "    etiqueta_num = float(etiqueta)\n",
    "    y_train.append(etiqueta_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62fb3993-3c47-479d-afe9-18b5f9fafd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "for name in test_images_files:\n",
    "    etiqueta = str(name)[-5]\n",
    "    etiqueta_num = float(etiqueta)\n",
    "    y_test.append(etiqueta_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c392d00-20e4-41f7-af6b-a96464103684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57135"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e591360-3f86-4746-a5a3-fea82514f6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivos\n",
      "-----------------\n",
      "Total: 78786.0\n",
      "-----------------\n",
      "Entrenamiento: 64466.0\n",
      "-----------------\n",
      "Prueba: 14320.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Revisamos números de positivos en conjuntos\n",
    "print(\n",
    "    f\"Positivos\\n\"\n",
    "    \"-----------------\\n\"\n",
    "    f\"Total: {sum(y_train) + sum(y_test)}\\n\"  # 277,524 tiles\n",
    "    \"-----------------\\n\"\n",
    "    f\"Entrenamiento: {sum(y_train) }\\n\"\n",
    "    \"-----------------\\n\"\n",
    "    f\"Prueba: {sum(y_test) }\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad4ddc-7776-4967-aa20-fbda4c4dc086",
   "metadata": {},
   "source": [
    "## Preparamos las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9a2a76d-cb9e-4273-a41d-af319d80aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cargamos de imágenes de entrenamiento en una lista\n",
    "dataset_img_train = []\n",
    "for img in train_images_files:\n",
    "    img_array = cv2.imread(str(img))\n",
    "    dataset_img_train.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e5a5ac7-850e-4f5d-849a-457001079fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aplanamos las imágenes\n",
    "data_set_img_train_plano = []\n",
    "for img in dataset_img_train:\n",
    "    img_plano = img.astype('float32') / 255\n",
    "    data_set_img_train_plano.append(img_plano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "541a7e20-af82-4b97-9409-21b1870cab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño del vector de resultados y de las imágenes es el mismo en el conjunto de entrenamiento\n"
     ]
    }
   ],
   "source": [
    "## Revisamos que tengan la misma longitud para el conjunto de entrenamiento\n",
    "leny_train = len(y_train)\n",
    "lenset_train = len(data_set_img_train_plano)\n",
    "\n",
    "if leny_train == lenset_train:\n",
    "    print(\"El tamaño del vector de resultados y de las imágenes es el mismo en el conjunto de entrenamiento\")\n",
    "else:\n",
    "    print(\"El tamaño del vector de resultados y las imágenes no coincide en el conjunto de entrenamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0552aa7-d034-4294-9279-08917ab2773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cargamos imágenes de prueba en una lista\n",
    "dataset_img_test = []\n",
    "for img in test_images_files:\n",
    "    img_array = cv2.imread(str(img))\n",
    "    dataset_img_test.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24d7e7c6-3eb5-4c99-ad31-03f1b324c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aplanamos las imágenes\n",
    "data_set_img_test_plano = []\n",
    "for img in dataset_img_test:\n",
    "    img_plano = img.astype('float32') / 255\n",
    "    data_set_img_test_plano.append(img_plano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80de5070-acc3-462b-bcd7-577b7b6cf065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño del vector de resultados y de las imágenes es el mismo en el conjunto de prueba\n"
     ]
    }
   ],
   "source": [
    "## Revisamos que tengan la misma longitud para el conjunto de prueba\n",
    "leny_test = len(y_test)\n",
    "lenset_test = len(data_set_img_test_plano)\n",
    "\n",
    "if leny_test == lenset_test:\n",
    "    print(\"El tamaño del vector de resultados y de las imágenes es el mismo en el conjunto de prueba\")\n",
    "else:\n",
    "    print(\"El tamaño del vector de resultados y las imágenes no coincide en el conjunto de prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aeaf50-5440-4de5-8f7f-6c732bc56a1b",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb93db94-200d-44a8-a136-3d2ddd36f9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
